{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncbSX2GtHDWc",
        "outputId": "3cafcdd6-036e-4dd6-9cb8-46c0d6fe526f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training samples: 50000, Image shape: (32, 32, 3)\n",
            "Epoch 1/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 42ms/step - accuracy: 0.3444 - loss: 1.7755 - val_accuracy: 0.5622 - val_loss: 1.2437\n",
            "Epoch 2/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 42ms/step - accuracy: 0.5827 - loss: 1.1945 - val_accuracy: 0.6206 - val_loss: 1.0824\n",
            "Epoch 3/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 42ms/step - accuracy: 0.6403 - loss: 1.0378 - val_accuracy: 0.6525 - val_loss: 1.0018\n",
            "Epoch 4/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 42ms/step - accuracy: 0.6707 - loss: 0.9508 - val_accuracy: 0.6658 - val_loss: 0.9711\n",
            "Epoch 5/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 42ms/step - accuracy: 0.6895 - loss: 0.8981 - val_accuracy: 0.6622 - val_loss: 0.9857\n",
            "Epoch 6/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 42ms/step - accuracy: 0.7064 - loss: 0.8507 - val_accuracy: 0.6804 - val_loss: 0.9352\n",
            "Epoch 7/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 42ms/step - accuracy: 0.7185 - loss: 0.8180 - val_accuracy: 0.6883 - val_loss: 0.9195\n",
            "Epoch 8/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 43ms/step - accuracy: 0.7287 - loss: 0.7755 - val_accuracy: 0.6822 - val_loss: 0.9413\n",
            "Epoch 9/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 42ms/step - accuracy: 0.7452 - loss: 0.7407 - val_accuracy: 0.6881 - val_loss: 0.9130\n",
            "Epoch 10/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 42ms/step - accuracy: 0.7502 - loss: 0.7191 - val_accuracy: 0.6918 - val_loss: 0.9167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test Accuracy (Keras Model): 69.18%\n",
            "\n",
            "Keras model saved as cifar10_cnn_classifier.h5\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, datasets\n",
        "import numpy as np\n",
        "\n",
        "# --- 1. Load Data (CIFAR-10) ---\n",
        "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Define class names for reporting\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "NUM_CLASSES = len(class_names)\n",
        "INPUT_SHAPE = x_train.shape[1:]  # (32, 32, 3)\n",
        "\n",
        "print(f\"Training samples: {x_train.shape[0]}, Image shape: {INPUT_SHAPE}\")\n",
        "\n",
        "# --- 2. Build Lightweight Model (Simple CNN) ---\n",
        "model = models.Sequential([\n",
        "    # Input layer and first Conv/Pool block\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=INPUT_SHAPE),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Second Conv/Pool block\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Classification head\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "])\n",
        "\n",
        "# --- 3. Compile and Train ---\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "EPOCHS = 10 # Increase for better accuracy, but longer training\n",
        "history = model.fit(x_train, y_train, epochs=EPOCHS,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    verbose=1)\n",
        "\n",
        "# --- 4. Evaluate and Save ---\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"\\nTest Accuracy (Keras Model): {test_accuracy*100:.2f}%\")\n",
        "\n",
        "model.save('cifar10_cnn_classifier.h5')\n",
        "print(\"\\nKeras model saved as cifar10_cnn_classifier.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALuFY4XjD-pM",
        "outputId": "8cfffc57-e894-4a50-fdc1-f33edbe55830"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved artifact at '/tmp/tmpv04y2xgs'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name='input_layer_1')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  136704935370320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136704935370128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136704935370896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136704935371280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136704935372048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136704935370512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136704935377808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136704935371856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "TFLite model saved as cifar10_cnn_classifier.tflite\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
            "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
            "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
            "    for details.\n",
            "    \n",
            "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "**TFLite Model Accuracy (Sample Test): 71.40%**\n"
          ]
        }
      ],
      "source": [
        "# --- 5. Convert Keras Model to TFLite ---\n",
        "TFLITE_FILE_PATH = 'cifar10_cnn_classifier.tflite'\n",
        "\n",
        "# Load the saved Keras model\n",
        "keras_model = tf.keras.models.load_model('cifar10_cnn_classifier.h5')\n",
        "\n",
        "# Convert the Keras model to a TFLite model\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TFLite model\n",
        "with open(TFLITE_FILE_PATH, 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(f\"TFLite model saved as {TFLITE_FILE_PATH}\")\n",
        "\n",
        "# --- 6. Load and Test TFLite Model ---\n",
        "interpreter = tf.lite.Interpreter(model_path=TFLITE_FILE_PATH)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output details\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Test on a subset of the test data (e.g., the first 1000 samples)\n",
        "num_samples = 1000\n",
        "x_sample = x_test[:num_samples]\n",
        "y_true = y_test[:num_samples].flatten()\n",
        "tflite_predictions = []\n",
        "\n",
        "# TFLite input requires specific type (usually float32)\n",
        "input_dtype = input_details[0]['dtype']\n",
        "\n",
        "for i in range(num_samples):\n",
        "    input_data = x_sample[i:i+1].astype(input_dtype)\n",
        "\n",
        "    # Set the tensor, invoke, and get output\n",
        "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "    interpreter.invoke()\n",
        "    tflite_output = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "    predicted_label = np.argmax(tflite_output[0])\n",
        "    tflite_predictions.append(predicted_label)\n",
        "\n",
        "tflite_accuracy = np.mean(tflite_predictions == y_true)\n",
        "print(f\"\\n**TFLite Model Accuracy (Sample Test): {tflite_accuracy*100:.2f}%**\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
